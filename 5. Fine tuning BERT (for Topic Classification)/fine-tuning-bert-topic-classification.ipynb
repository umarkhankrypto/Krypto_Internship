{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9427408,"sourceType":"datasetVersion","datasetId":5726933}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import TFBertForSequenceClassification, BertTokenizer\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"7Og0BtVxu_jz","execution":{"iopub.status.busy":"2024-09-18T14:44:44.486017Z","iopub.execute_input":"2024-09-18T14:44:44.486393Z","iopub.status.idle":"2024-09-18T14:45:03.403842Z","shell.execute_reply.started":"2024-09-18T14:44:44.486360Z","shell.execute_reply":"2024-09-18T14:45:03.402787Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T14:45:03.405604Z","iopub.execute_input":"2024-09-18T14:45:03.406188Z","iopub.status.idle":"2024-09-18T14:45:03.414664Z","shell.execute_reply.started":"2024-09-18T14:45:03.406152Z","shell.execute_reply":"2024-09-18T14:45:03.413675Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained BERT model for sequence classification with 4 topic classes\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-5Val8Ku_j3","outputId":"ce14b03f-0fea-42e8-dba7-79919978c5c3","execution":{"iopub.status.busy":"2024-09-18T14:45:03.416632Z","iopub.execute_input":"2024-09-18T14:45:03.417593Z","iopub.status.idle":"2024-09-18T14:45:09.137152Z","shell.execute_reply.started":"2024-09-18T14:45:03.417512Z","shell.execute_reply":"2024-09-18T14:45:09.136071Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab80defcd619476aaf3e7f3b456988ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515ab4fd138e4e3e9c47836e0698ff66"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ec6394a17ae4c86bdb7406823233299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac4ceb3930145559df164bd3ea67c3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cfae6268fd7470aadf0342513ac175c"}},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKy_Tyu0zcFn","outputId":"6549e813-a006-4eeb-f83c-0129b86c93ec","execution":{"iopub.status.busy":"2024-09-18T14:45:09.139701Z","iopub.execute_input":"2024-09-18T14:45:09.140051Z","iopub.status.idle":"2024-09-18T14:45:09.182633Z","shell.execute_reply.started":"2024-09-18T14:45:09.140015Z","shell.execute_reply":"2024-09-18T14:45:09.181628Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bert (TFBertMainLayer)      multiple                  109482240 \n                                                                 \n dropout_37 (Dropout)        multiple                  0 (unused)\n                                                                 \n classifier (Dense)          multiple                  3076      \n                                                                 \n=================================================================\nTotal params: 109485316 (417.65 MB)\nTrainable params: 109485316 (417.65 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the model configuration\nmodel_config = model.get_config()\nprint(model_config)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcNvXpPMz5tm","outputId":"b0223765-9bc7-49a3-916c-fba0e504052e","execution":{"iopub.status.busy":"2024-09-18T14:45:09.183704Z","iopub.execute_input":"2024-09-18T14:45:09.184030Z","iopub.status.idle":"2024-09-18T14:45:09.189737Z","shell.execute_reply.started":"2024-09-18T14:45:09.183996Z","shell.execute_reply":"2024-09-18T14:45:09.188644Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['BertForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': 0, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'bert-base-uncased', 'transformers_version': '4.44.0', 'gradient_checkpointing': False, 'model_type': 'bert', 'vocab_size': 30522, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 512, 'type_vocab_size': 2, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12, 'position_embedding_type': 'absolute', 'use_cache': True, 'classifier_dropout': None}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Count the number of layers in the model\nnum_layers = len(model.layers)\nprint(f\"Total number of layers: {num_layers}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSZwCsO30vBB","outputId":"daf19e86-a868-4c21-d714-ec2bc3743e24","execution":{"iopub.status.busy":"2024-09-18T14:45:09.191366Z","iopub.execute_input":"2024-09-18T14:45:09.192261Z","iopub.status.idle":"2024-09-18T14:45:09.198961Z","shell.execute_reply.started":"2024-09-18T14:45:09.192221Z","shell.execute_reply":"2024-09-18T14:45:09.197943Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total number of layers: 3\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_model = model.bert\n\n# Count the number of encoder layers\nnum_encoder_layers = len(bert_model.encoder.layer)\n\nprint(f\"Number of transformer layers (encoder layers) in BERT: {num_encoder_layers}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQvMxK5_1Ui2","outputId":"3440ccbe-085f-43ff-e8f1-1d80329ab235","execution":{"iopub.status.busy":"2024-09-18T14:45:09.200383Z","iopub.execute_input":"2024-09-18T14:45:09.200881Z","iopub.status.idle":"2024-09-18T14:45:09.209734Z","shell.execute_reply.started":"2024-09-18T14:45:09.200790Z","shell.execute_reply":"2024-09-18T14:45:09.208804Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of transformer layers (encoder layers) in BERT: 12\n","output_type":"stream"}]},{"cell_type":"code","source":"# Freeze the first 8 layers of the BERT encoder\nfor layer in model.bert.encoder.layer[:8]:\n    layer.trainable = False  # Freezing layers\n\n# Check which layers are frozen\nfor layer_num, layer in enumerate(model.bert.encoder.layer):\n    print(f\"Layer {layer_num}: {'trainable' if layer.trainable else 'frozen'}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnF4kzjyu_j4","outputId":"c6c7556c-5cfe-41ab-aa2e-4d66d37ed531","execution":{"iopub.status.busy":"2024-09-18T14:45:09.210903Z","iopub.execute_input":"2024-09-18T14:45:09.211218Z","iopub.status.idle":"2024-09-18T14:45:09.225765Z","shell.execute_reply.started":"2024-09-18T14:45:09.211185Z","shell.execute_reply":"2024-09-18T14:45:09.224683Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Layer 0: frozen\nLayer 1: frozen\nLayer 2: frozen\nLayer 3: frozen\nLayer 4: frozen\nLayer 5: frozen\nLayer 6: frozen\nLayer 7: frozen\nLayer 8: trainable\nLayer 9: trainable\nLayer 10: trainable\nLayer 11: trainable\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load dataset (ensure it has 'text' and 'label' columns)\ndf = pd.read_csv('/kaggle/input/topic-classification/dataset.csv')","metadata":{"id":"yob9s4wcu_j4","execution":{"iopub.status.busy":"2024-09-18T14:45:09.227322Z","iopub.execute_input":"2024-09-18T14:45:09.227696Z","iopub.status.idle":"2024-09-18T14:45:09.527319Z","shell.execute_reply.started":"2024-09-18T14:45:09.227656Z","shell.execute_reply":"2024-09-18T14:45:09.526137Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Av5VUO1su_j4","outputId":"c789038b-9e7d-4280-ad72-d3c316fcf00b","execution":{"iopub.status.busy":"2024-09-18T14:45:09.531139Z","iopub.execute_input":"2024-09-18T14:45:09.531630Z","iopub.status.idle":"2024-09-18T14:45:09.550915Z","shell.execute_reply.started":"2024-09-18T14:45:09.531587Z","shell.execute_reply":"2024-09-18T14:45:09.549904Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Wall St. Bears Claw Back Into the Black (Reute...      2\n1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n4  Oil prices soar to all-time record, posing new...      2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oil prices soar to all-time record, posing new...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"qRotfqwqu_j5","outputId":"9291908f-dbb0-49b8-ae63-4c2900eb0b03","execution":{"iopub.status.busy":"2024-09-18T14:45:09.552212Z","iopub.execute_input":"2024-09-18T14:45:09.552577Z","iopub.status.idle":"2024-09-18T14:45:09.567632Z","shell.execute_reply.started":"2024-09-18T14:45:09.552537Z","shell.execute_reply":"2024-09-18T14:45:09.566304Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"text     0\nlabel    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfftSg4xu_j5","outputId":"957c5f9b-36bf-4c22-a883-c62a7cb8887b","execution":{"iopub.status.busy":"2024-09-18T14:45:09.569242Z","iopub.execute_input":"2024-09-18T14:45:09.569608Z","iopub.status.idle":"2024-09-18T14:45:09.576606Z","shell.execute_reply.started":"2024-09-18T14:45:09.569572Z","shell.execute_reply":"2024-09-18T14:45:09.575610Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(50000, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df[\"label\"].unique()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7H0Exsqu_j5","outputId":"3cfcdb6f-28a9-43bc-8d99-45a5bfb875f7","execution":{"iopub.status.busy":"2024-09-18T14:45:09.577902Z","iopub.execute_input":"2024-09-18T14:45:09.578220Z","iopub.status.idle":"2024-09-18T14:45:09.591298Z","shell.execute_reply.started":"2024-09-18T14:45:09.578186Z","shell.execute_reply":"2024-09-18T14:45:09.590269Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([2, 3, 1, 0])"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGmgNUw4u_j6","outputId":"c3ee003c-7bf2-4d38-f9b5-27fe234492b6","execution":{"iopub.status.busy":"2024-09-18T14:45:09.592650Z","iopub.execute_input":"2024-09-18T14:45:09.592997Z","iopub.status.idle":"2024-09-18T14:45:09.600349Z","shell.execute_reply.started":"2024-09-18T14:45:09.592960Z","shell.execute_reply":"2024-09-18T14:45:09.599315Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Index(['text', 'label'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# Split the data into train and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42\n)","metadata":{"id":"Cu8wi-PAu_j6","execution":{"iopub.status.busy":"2024-09-18T14:45:09.601752Z","iopub.execute_input":"2024-09-18T14:45:09.602235Z","iopub.status.idle":"2024-09-18T14:45:09.639641Z","shell.execute_reply.started":"2024-09-18T14:45:09.602188Z","shell.execute_reply":"2024-09-18T14:45:09.638868Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Tokenize the text data\ndef tokenize_data(texts, tokenizer, max_len=512):\n    return tokenizer(\n        texts,\n        padding=True,\n        truncation=True,\n        max_length=max_len,\n        return_tensors='tf'\n    )","metadata":{"id":"4xyaOaFiu_j7","execution":{"iopub.status.busy":"2024-09-18T14:45:09.640820Z","iopub.execute_input":"2024-09-18T14:45:09.641173Z","iopub.status.idle":"2024-09-18T14:45:09.646399Z","shell.execute_reply.started":"2024-09-18T14:45:09.641137Z","shell.execute_reply":"2024-09-18T14:45:09.645405Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenize_data(train_texts, tokenizer)\nval_encodings = tokenize_data(val_texts, tokenizer)","metadata":{"id":"LgSQvgqru_j7","execution":{"iopub.status.busy":"2024-09-18T14:45:09.647686Z","iopub.execute_input":"2024-09-18T14:45:09.648080Z","iopub.status.idle":"2024-09-18T14:46:39.654944Z","shell.execute_reply.started":"2024-09-18T14:45:09.648036Z","shell.execute_reply":"2024-09-18T14:46:39.653882Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Create TensorFlow dataset objects\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels)).batch(16)\nval_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings), val_labels)).batch(16)","metadata":{"id":"db3bRi4vu_j7","execution":{"iopub.status.busy":"2024-09-18T14:46:39.656138Z","iopub.execute_input":"2024-09-18T14:46:39.656443Z","iopub.status.idle":"2024-09-18T14:46:39.835252Z","shell.execute_reply.started":"2024-09-18T14:46:39.656410Z","shell.execute_reply":"2024-09-18T14:46:39.834197Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","metadata":{"id":"CE-WwZsWu_j7","execution":{"iopub.status.busy":"2024-09-18T14:46:39.836414Z","iopub.execute_input":"2024-09-18T14:46:39.836714Z","iopub.status.idle":"2024-09-18T14:46:39.963787Z","shell.execute_reply.started":"2024-09-18T14:46:39.836681Z","shell.execute_reply":"2024-09-18T14:46:39.963007Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZemgMOoLxPC8","outputId":"e4d8c772-45ed-44b0-e734-9d8a1f3a05fc","execution":{"iopub.status.busy":"2024-09-18T14:46:39.964943Z","iopub.execute_input":"2024-09-18T14:46:39.965238Z","iopub.status.idle":"2024-09-18T14:46:40.005699Z","shell.execute_reply.started":"2024-09-18T14:46:39.965205Z","shell.execute_reply":"2024-09-18T14:46:40.004863Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bert (TFBertMainLayer)      multiple                  109482240 \n                                                                 \n dropout_37 (Dropout)        multiple                  0 (unused)\n                                                                 \n classifier (Dense)          multiple                  3076      \n                                                                 \n=================================================================\nTotal params: 109485316 (417.65 MB)\nTrainable params: 52782340 (201.35 MB)\nNon-trainable params: 56702976 (216.30 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-tune the model\nhistory = model.fit(train_dataset, validation_data=val_dataset, epochs=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmAOgMRru_j7","outputId":"adb2a8e4-d8c5-4468-e4e9-e2ab23d81140","execution":{"iopub.status.busy":"2024-09-18T14:46:40.006946Z","iopub.execute_input":"2024-09-18T14:46:40.007333Z","iopub.status.idle":"2024-09-18T15:34:52.490204Z","shell.execute_reply.started":"2024-09-18T14:46:40.007275Z","shell.execute_reply":"2024-09-18T15:34:52.489306Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"WARNING: AutoGraph could not transform <function infer_framework at 0x78ff99a6fe20> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1726670875.283759     103 service.cc:145] XLA service 0x78fade127330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1726670875.283840     103 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1726670875.283848     103 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1726670875.464843     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"2500/2500 [==============================] - 2892s 1s/step - loss: 0.2650 - accuracy: 0.9107 - val_loss: 0.1942 - val_accuracy: 0.9338\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract history for accuracy, loss, validation accuracy, and validation loss\ntraining_accuracy = history.history.get('accuracy', [])\ntraining_loss = history.history.get('loss', [])\nvalidation_accuracy = history.history.get('val_accuracy', [])\nvalidation_loss = history.history.get('val_loss', [])\n\n# Print the training accuracy history\nprint(\"Training Accuracy History:\")\nprint(training_accuracy)\n\n# Print the training loss history\nprint(\"\\nTraining Loss History:\")\nprint(training_loss)\n\n# Print the validation accuracy history\nprint(\"\\nValidation Accuracy History:\")\nprint(validation_accuracy)\n\n# Print the validation loss history\nprint(\"\\nValidation Loss History:\")\nprint(validation_loss)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52fCBICsA0gK","outputId":"ef54b97a-9e0f-4907-dba8-0f1732ee9e9d","execution":{"iopub.status.busy":"2024-09-18T15:36:05.415349Z","iopub.execute_input":"2024-09-18T15:36:05.415718Z","iopub.status.idle":"2024-09-18T15:36:05.423102Z","shell.execute_reply.started":"2024-09-18T15:36:05.415683Z","shell.execute_reply":"2024-09-18T15:36:05.422034Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Training Accuracy History:\n[0.9106500148773193]\n\nTraining Loss History:\n[0.2649601995944977]\n\nValidation Accuracy History:\n[0.9337999820709229]\n\nValidation Loss History:\n[0.19422510266304016]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict topic for a new text\ncategory_mapping = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n\ndef predict_topic(text, model, tokenizer, category_mapping):\n    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=512)\n    outputs = model(inputs)\n    prediction = tf.argmax(outputs.logits, axis=-1).numpy()[0]\n    return category_mapping[prediction]\n\n# Example usage\ntext = \"The stock market is experiencing volatility due to recent global events.\"\npredicted_topic = predict_topic(text, model, tokenizer, category_mapping)\nprint(f'Predicted Topic: {predicted_topic}')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scfIfcjRu_j8","outputId":"85151d64-b0eb-4a7f-e740-00301bec7bc9","execution":{"iopub.status.busy":"2024-09-18T15:36:05.424757Z","iopub.execute_input":"2024-09-18T15:36:05.425456Z","iopub.status.idle":"2024-09-18T15:36:05.718413Z","shell.execute_reply.started":"2024-09-18T15:36:05.425411Z","shell.execute_reply":"2024-09-18T15:36:05.717475Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Predicted Topic: Business\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model in Hugging Face format\nmodel.save_pretrained('fine_tuned_bert_model')\n\n# Save the tokenizer\ntokenizer.save_pretrained('fine_tuned_bert_model')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T15:36:05.719724Z","iopub.execute_input":"2024-09-18T15:36:05.720635Z","iopub.status.idle":"2024-09-18T15:36:06.812366Z","shell.execute_reply.started":"2024-09-18T15:36:05.720587Z","shell.execute_reply":"2024-09-18T15:36:06.811399Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"('fine_tuned_bert_model/tokenizer_config.json',\n 'fine_tuned_bert_model/special_tokens_map.json',\n 'fine_tuned_bert_model/vocab.txt',\n 'fine_tuned_bert_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\n\n# Zip the model directory\nshutil.make_archive('fine_tuned_bert_model', 'zip', 'fine_tuned_bert_model')\n\n# Download the zipped model\nfrom IPython.display import FileLink\nFileLink(r'fine_tuned_bert_model.zip')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T15:37:32.836952Z","iopub.execute_input":"2024-09-18T15:37:32.837356Z","iopub.status.idle":"2024-09-18T15:38:42.221245Z","shell.execute_reply.started":"2024-09-18T15:37:32.837318Z","shell.execute_reply":"2024-09-18T15:38:42.220299Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine_tuned_bert_model.zip","text/html":"<a href='fine_tuned_bert_model.zip' target='_blank'>fine_tuned_bert_model.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}